{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import pandas\nimport pandas as pd\n\n# Load dataset\ncc_apps = pd.read_csv('/notebooks/data.csv')\n\n# Inspect data\ncc_apps.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#  2. Inspecting the applications\n\n# Print summary statistics\ncc_apps_description = cc_apps.describe()\nprint(cc_apps_description)\n\nprint(\"\\n\")\n\n# Print DataFrame information\ncc_apps_info = cc_apps.info()\nprint(cc_apps_info)\n\nprint(\"\\n\")\n\n# Inspect missing values in the dataset\ncc_apps.tail(17)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# 3. Handling the missing values (part i)\n\n# Import numpy\nimport numpy as np\n\n# Inspect missing values in the dataset\nprint(cc_apps.isnull().values.sum())\n\n# Replace the '?'s with NaN\ncc_apps = cc_apps.replace('?', np.nan)\n\n# Inspect the missing values again\nprint('Total NaN: ' + str(cc_apps.isnull().values.sum()))\nprint('NaN by column:' '\\n')  \nprint(cc_apps.isnull().sum())\ncc_apps.tail(17)\n\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# 4. Handling the missing values (part ii)\n\n# Impute the missing values with mean imputation\ncc_apps.fillna(cc_apps.mean(), inplace=True)\n\n# Count the number of NaNs in the dataset to verify\nprint('Total NaN: ' + str(cc_apps.isnull().values.sum()))\ncc_apps.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#   5. Handling the missing values (part iii)\n\n# Iterate over each column of cc_apps\nfor col in cc_apps:\n    # Check if the column is of object type\n    if cc_apps[col].dtypes == 'object':\n        # Impute with the most frequent value\n        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])\n\n# Count the number of NaNs in the dataset and print the counts to verify\nprint('Total missing values:' + str(cc_apps.isnull().values.sum()))\nprint('Missing values in each column:')\ncc_apps.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#     6. Preprocessing the data (part i) \n\n# Import LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\n# Instantiate LabelEncoder\nle = LabelEncoder()\n# Iterate over all the values of each column and extract their dtypes\nfor col in cc_apps:\n    # Compare if the dtype is object\n    if cc_apps[col].dtypes =='object':\n    # Use LabelEncoder to do the numeric transformation\n        le.fit(cc_apps[col])\n        cc_apps[col]=le.transform(cc_apps[col])\n#  information of the new dataframe\ncc_apps.info()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#  7. Splitting the dataset into train and test sets\n\n# Import train_test_split\nfrom sklearn.model_selection import train_test_split\n\n# Drop the features 11 and 13 and convert the DataFrame to a NumPy array\ncc_apps = cc_apps.drop([11, 13], axis=1)\nprint(cc_apps.head())\ncc_apps = cc_apps.values\n\n# Segregate features and labels into separate variables\nX,y = cc_apps[:,0:12] , cc_apps[:,13]\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                y,\n                                test_size=0.33,\n                                random_state=42)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#  8. Preprocessing the data (part ii)\n\n# Import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Instantiate MinMaxScaler and use it to rescale X_train and X_test\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX_train = scaler.fit_transform(X_train)\nrescaledX_test = scaler.fit_transform(X_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#  9. Fitting a logistic regression model to the train set\n\n# Import LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\n# Instantiate a LogisticRegression classifier with default parameter values\nlogreg = LogisticRegression()\n\n# Fit logreg to the train set\nlogreg.fit(rescaledX_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#  10. Making predictions and evaluating performance\n\n# Import confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n# Use logreg to predict instances from the test set and store it\ny_pred = logreg.predict(rescaledX_test)\n\n# Get the accuracy score of logreg model and print it\nprint(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n\n# Print the confusion matrix of the logreg model\nprint('Confusion matrix: \\n ', confusion_matrix(y_test, y_pred))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# 11. Grid searching and making the model perform better\n\n# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n# Define the grid of values for tol and max_iter\ntol = [0.01, 0.001, 0.0001]\nmax_iter = [100, 150, 200]\n\n# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\nparam_grid = dict(tol= tol, max_iter= max_iter)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#  12. Finding the best performing model\n\n# Instantiate GridSearchCV with the required parameters\ngrid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n\n# Use scaler to rescale X and assign it to rescaledX\nrescaledX = scaler.fit_transform(X)\n\n# Fit data to grid_model\ngrid_model_result = grid_model.fit(rescaledX, y)\n\n# Summarize results\nbest_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\nprint(\"Best: %f using %s\" % (best_score, best_params))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}